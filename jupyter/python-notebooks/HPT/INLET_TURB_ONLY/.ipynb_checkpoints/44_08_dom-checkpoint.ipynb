{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Platus library demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading all the packages and own libraries that are needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/IPython/kernel/__init__.py:13: ShimWarning: The `IPython.kernel` package has been deprecated. You should import from ipykernel or jupyter_client instead.\n",
      "  \"You should import from ipykernel or jupyter_client instead.\", ShimWarning)\n"
     ]
    }
   ],
   "source": [
    "# General modules and packages\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import shutil\n",
    "import os\n",
    "import pylab as pl\n",
    "pl.rc('text', usetex=True)\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "%matplotlib notebook \n",
    "\n",
    "# other downloaded modules\n",
    "from matplotlib2tikz import save as tikz_save\n",
    "\n",
    "#own modules\n",
    "import tools\n",
    "import lib_hipstar as lh\n",
    "import lines\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the output of the post processing in Hipstar - Convergence Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step the output from the statistics postprocessing is generated. It has to result in the file 'STAT\\_cont.bin'. This is only implemented in the 'branches/RSM\\_budget2' yet but will be released in the November 2014 for general use in the trunk.\n",
    "In order to be used with old statistics files 'Sfile\\_r?\\_???' the option for the the istat(option for statistic post-processing, second entry in the second last line of the infile) in the HiPSTAR postprocessing infile has to be set to 5. If 'istat' is set to 4 during simulation time the output will be \"Sfile\\_b?\\_???\" and the same option can be used in the the postprocessing.\n",
    "\n",
    "Now switch to your working data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/drive2/HPT/INLET_TURB_ONLY/43_60dom\n"
     ]
    }
   ],
   "source": [
    "cd ~/drive2/HPT/INLET_TURB_ONLY/43_60dom/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a tool now to get information on the collected timesteps. Essentially it extracts the timesteps from the filename of the Sfiles and if a hipstar infile is given it gets the dt from there and computes how many flow through times (ftts) were collected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestep of simulation was  0.00015\n",
      "    #            File Timestep               # of steps           ftts until end                   nnstat\n",
      "    0                    10000                        -                        -                        -\n",
      "    1                    20000                    90200                  13.5300                    10000\n",
      "    2                    30000                    80200                  12.0300                    10000\n",
      "    3                    40000                    70200                  10.5300                    10000\n",
      "    4                    40100                    60200                   9.0300                      100\n",
      "    5                    40200                    60100                   9.0150                      100\n",
      "    6                    50200                    60000                   9.0000                    10000\n",
      "    7                    60200                    50000                   7.5000                    10000\n",
      "    8                    70200                    40000                   6.0000                    10000\n",
      "    9                    80200                    30000                   4.5000                    10000\n",
      "   10                    90200                    20000                   3.0000                    10000\n",
      "   11                   100200                    10000                   1.5000                    10000\n"
     ]
    }
   ],
   "source": [
    "tools.sfile_intervalls('Sfiles',infile='inlet_turb_new_mon.in')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step we perform the Hipstar postprocessing. There exists a tool that allows to perform several runs of the postprocessing to perform a statistical convergence analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is case: /media/drive2/HPT/INLET_TURB_ONLY/43_60dom/\n",
      "working on:\n",
      "20000_to_40000 corresponding to 3.0time units\n",
      "working on:\n",
      "50200_to_100200 corresponding to 7.5time units\n",
      "working on:\n",
      "50200_to_70200 corresponding to 3.0time units\n"
     ]
    }
   ],
   "source": [
    "# first create a case instance that gathers the most important information of a case\n",
    "thiscase=lh.case(os.getcwd(),infile='inlet_turb_new_mon.in')\n",
    "# next we need to define the intervalls that we want to compare, \n",
    "# they are given by the start and end timestep\n",
    "intervall=[]\n",
    "intervall.append([20000,40000])\n",
    "intervall.append([50200,100200])\n",
    "intervall.append([50200,70200])\n",
    "# now we can run the convergence test:\n",
    "thiscase.runconvergence(intervall,pexec=\"inlet_turb_post.x\")\n",
    "# note that it assumes that the postprocessing executable is 'post.x' \n",
    "# and will put all the results in a subfolder that will be created \n",
    "# named convergence. Furthermore it uses statistics \n",
    "# option 4 (last number in the last line of the input file) \n",
    "# you can change any/all of these defaults by:\n",
    "# thiscase.runconvergence(intervall,pexec='postpro.x',outputdir='convergence',statoption=4,runtimeopt=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the output of the convergence test and use the lines library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract data from all the files generated during the convergence test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting line\n",
      "Found 200 points.\n",
      "Extracting line\n",
      "Found 200 points.\n",
      "Extracting line\n",
      "Found 200 points.\n"
     ]
    }
   ],
   "source": [
    "# first initialize the lines object (which is a handle for multiple line objects, \n",
    "# for details refer to the wiki) with the convergence=True flag\n",
    "comparecases=lines.lines(convergence=True) \n",
    "# extract a profile now defined by point 1 and 2 and the number of \n",
    "# points that shall be extracted between the two\n",
    "p1 = [-1.11,0.1] ; p2 = [-0.2,0.1]\n",
    "# note that there is many more options to control the exact behaviour of the \n",
    "# extr_line method, \n",
    "# check them by executing comparecases.extr_line?\n",
    "# However the only options that are required by the tool are the coordinates \n",
    "# of the start and end point, the number of points that should be extracted\n",
    "# and in case the convergence=True flag would not have been set, a filename\n",
    "comparecases.extr_line(p1,p2,200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now plot and compare the extracted data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Straight line extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now compare and plot certain variables. It is the same with the options for that tool as before, there are a lot of possibilities to adjust the exact appearance of the plot. \n",
    "However the minimal input required is which data should be plotted on the x- and y-axis respectively. If it is a list of integers for any of the axis it'll be a plot with several sub-plots. For example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plotvars=[]\n",
    "plotvars.append(comparecases.l[0].var.get_index(101,1))\n",
    "plotvars.append(comparecases.l[0].var.get_index(101,2))\n",
    "plotvars.append(comparecases.l[0].var.get_index(101,10))\n",
    "comparecases.plot_var([0],plotvars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idy=[]\n",
    "idy.append(comparecases.l[0].var.get_index(101,10))\n",
    "idy.append(comparecases.l[0].var.get_index(101,12))\n",
    "idy.append(comparecases.l[0].var.get_index(101,13))\n",
    "plt.figure()\n",
    "l=2\n",
    "for i in idy:\n",
    "    plt.plot(comparecases.l[l].data[:,0],-comparecases.l[l].data[:,i],label=comparecases.l[l].var.vars[i])\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
